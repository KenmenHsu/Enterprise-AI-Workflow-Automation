import os
import time
import asyncio
import json
from collections import defaultdict
from pathlib import Path
from datetime import datetime

import requests
import pandas as pd
from pypdf import PdfReader
from docx import Document
from fastapi import FastAPI, BackgroundTasks
from pydantic import BaseModel
from fastapi.middleware.cors import CORSMiddleware
import uvicorn
import win32security  # Windows å°ˆç”¨æ¬Šé™å¥—ä»¶

# å¼•å…¥ dotenv ä»¥è®€å–ç’°å¢ƒè®Šæ•¸ (æ¨¡æ“¬çœŸå¯¦é–‹ç™¼ç’°å¢ƒ)
from dotenv import load_dotenv

# è¼‰å…¥ .env è¨­å®š
load_dotenv()

app = FastAPI(title="Enterprise AI Workflow Automation")

# ==========================================
# ğŸ”” è¨­å®šå€ (å¾ç’°å¢ƒè®Šæ•¸è®€å–ï¼Œç¢ºä¿è³‡å®‰)
# ==========================================
TEAMS_WEBHOOK_URL = os.getenv("TEAMS_WEBHOOK_URL", "")
OLLAMA_API_URL = os.getenv("OLLAMA_API_URL", "http://localhost:11434/api/generate")
AI_MODEL = os.getenv("AI_MODEL", "qwen2.5:3b")

# å…è¨±è·¨åŸŸè«‹æ±‚ (CORS)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ==========================================
# ğŸ“‚ æª”æ¡ˆè·¯å¾‘è¨­å®š
# ==========================================
# æ³¨æ„ï¼šåœ¨å¯¦éš›éƒ¨ç½²æ™‚ï¼Œè«‹ä¿®æ”¹ç‚ºå¯¦éš›çš„ NAS æˆ–å…§ç¶²æ›è¼‰è·¯å¾‘
SEARCH_DIRS = [
    # Path(r"\\192.168.1.10\Public\Project_Docs"),  # ç¯„ä¾‹ï¼šå…¬å¸å…§ç¶²è·¯å¾‘
    Path("./demo_data/documents"),                 # ç¯„ä¾‹ï¼šæœ¬åœ°æ¸¬è©¦è·¯å¾‘
    Path("C:/Users/User/Documents/Projects"),      # ç¯„ä¾‹ï¼šæœ¬åœ°æ–‡ä»¶
]

# æ™ºæ…§é—œéµå­—å®šç¾© (ç”¨æ–¼è‡ªå‹•åˆ†é¡å°ˆæ¡ˆ)
PROJECT_DEFINITIONS = {
    "Project-Alpha": ["Alpha", "Gen1"],
    "Project-Beta":  ["Beta"],
    "Project-Gamma": ["Gamma", "Monitoring"],
}

# å¿½ç•¥æ¸…å–® (é»‘åå–®)
IGNORED_DIRS = {".git", ".vscode", "__pycache__", "node_modules", "Backup", "Temp"}
IGNORED_EXTENSIONS = {".dll", ".exe", ".tmp", ".log", ".bak"}

# éœ€è¦æƒææ“æœ‰è€…çš„æª”æ¡ˆé¡å‹
OWNER_LOOKUP_EXTENSIONS = {".pdf", ".doc", ".docx", ".xls", ".xlsx", ".ppt", ".pptx"}


# ==========================================
# ğŸ› ï¸ æ ¸å¿ƒåŠŸèƒ½å‡½å¼
# ==========================================

def send_teams_card(title, summary, facts):
    """
    ç™¼é€ Adaptive Card åˆ° Microsoft Teams
    """
    if not TEAMS_WEBHOOK_URL or "http" not in TEAMS_WEBHOOK_URL:
        print("âš ï¸ æœªè¨­å®š Teams Webhookï¼Œè·³éé€šçŸ¥")
        return

    adaptive_facts = [{"title": f['name'], "value": f['value']} for f in facts]
    
    card_payload = {
        "type": "message",
        "attachments": [{
            "contentType": "application/vnd.microsoft.card.adaptive",
            "content": {
                "$schema": "http://adaptivecards.io/schemas/adaptive-card.json",
                "type": "AdaptiveCard",
                "version": "1.4",
                "body": [
                    {"type": "TextBlock", "text": title, "weight": "Bolder", "size": "Medium", "color": "Accent"},
                    {"type": "TextBlock", "text": f"Time: {datetime.now().strftime('%Y-%m-%d %H:%M')}", "isSubtle": True, "size": "Small"},
                    {"type": "FactSet", "facts": adaptive_facts},
                    {"type": "TextBlock", "text": "ğŸ“Š AI Analysis Summary:", "weight": "Bolder", "size": "Small", "separator": True},
                    {"type": "TextBlock", "text": summary, "wrap": True, "size": "Small"}
                ]
            }
        }]
    }

    try:
        requests.post(TEAMS_WEBHOOK_URL, json=card_payload, headers={'Content-Type': 'application/json'})
    except Exception as e:
        print(f"âŒ Teams ç™¼é€å¤±æ•—: {e}")


def read_file_content(file_path):
    """
    å¤šæ ¼å¼æª”æ¡ˆè®€å–å™¨ (æ”¯æ´ PDF, Docx, Excel, Code)
    """
    path = Path(file_path)
    ext = path.suffix.lower()
    content = ""
    
    try:
        if ext in ['.c', '.h', '.cpp', '.py', '.js', '.txt', '.md', '.json']:
            with open(path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
                
        elif ext == '.pdf':
            reader = PdfReader(path)
            for page in reader.pages[:30]: # é™åˆ¶é æ•¸
                text = page.extract_text()
                if text: content += text + "\n"
            if not content.strip(): return "[ç³»çµ±è­¦å‘Šï¼šç„¡æ³•è®€å– PDF æ–‡å­—ï¼Œå¯èƒ½æ˜¯æƒææª”]"

        elif ext == '.docx':
            doc = Document(path)
            content = "\n".join([para.text for para in doc.paragraphs])
            
        elif ext in ['.xlsx', '.xls']:
            xls = pd.ExcelFile(path)
            for sheet_name in xls.sheet_names:
                df = pd.read_excel(xls, sheet_name=sheet_name, nrows=400) # é™åˆ¶è¡Œæ•¸
                content += f"\n=== Sheet: {sheet_name} ===\n" + df.to_csv(index=False)

        else:
            return f"[ä¸æ”¯æ´çš„æ ¼å¼ï¼š{ext}]"

        return content[:5000] # é™åˆ¶å­—æ•¸ä»¥é˜² Token è¶…å‡º
        
    except Exception as e:
        return f"[è®€å–éŒ¯èª¤ï¼š{str(e)}]"


def get_file_owner(path_str):
    """å–å¾— Windows æª”æ¡ˆæ“æœ‰è€… (éœ€ Windows ç’°å¢ƒ)"""
    try:
        sd = win32security.GetFileSecurity(path_str, win32security.OWNER_SECURITY_INFORMATION)
        owner_sid = sd.GetSecurityDescriptorOwner()
        name, _, _ = win32security.LookupAccountSid(None, owner_sid)
        return name
    except:
        return "Unknown"


def determine_project(file_path_obj):
    """æ ¹æ“šæª”åèˆ‡è·¯å¾‘é—œéµå­—åˆ¤æ–·æ‰€å±¬å°ˆæ¡ˆ"""
    full_path = str(file_path_obj).lower()
    filename = file_path_obj.name.lower()
    scores = {}
    
    for project, keywords in PROJECT_DEFINITIONS.items():
        score = 0
        for kw in keywords:
            kw_lower = kw.lower()
            if kw_lower in filename: score += 10
            elif kw_lower in full_path: score += 3
        if score > 0: scores[project] = score
            
    return max(scores, key=scores.get) if scores else "Uncategorized"


def internal_scan_files():
    """æƒææŒ‡å®šç›®éŒ„ä¸‹çš„æ‰€æœ‰æª”æ¡ˆ"""
    all_results = []
    for base_dir in SEARCH_DIRS:
        if not base_dir.exists(): continue
        for root, dirs, files in os.walk(base_dir):
            dirs[:] = [d for d in dirs if d not in IGNORED_DIRS] # éæ¿¾è³‡æ–™å¤¾
            for file in files:
                file_path = Path(root) / file
                if file_path.suffix.lower() in IGNORED_EXTENSIONS: continue
                
                try:
                    stat = file_path.stat()
                    if stat.st_size == 0: continue
                    
                    all_results.append({
                        "filename": file_path.name,
                        "path": str(file_path),
                        "project": determine_project(file_path),
                        "updated_at": datetime.fromtimestamp(stat.st_mtime).strftime('%Y-%m-%d %H:%M'),
                        "owner": get_file_owner(str(file_path)) if file_path.suffix.lower() in OWNER_LOOKUP_EXTENSIONS else "",
                        "raw_mtime": stat.st_mtime
                    })
                except: pass
    
    all_results.sort(key=lambda x: x['raw_mtime'], reverse=True)
    return all_results

# ==========================================
# ğŸš€ API è·¯ç”±å€
# ==========================================

class AnalyzeRequest(BaseModel):
    files: list

@app.post("/api/analyze_local")
def analyze_local_files(request: AnalyzeRequest):
    """æ¥æ”¶æª”æ¡ˆæ¸…å–®ï¼Œå‘¼å« Local LLM é€²è¡Œåˆ†æ"""
    context = "ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„å°ˆæ¡ˆç¶“ç†ã€‚è«‹ç¸½çµä»¥ä¸‹æª”æ¡ˆé‡é»ï¼š\n\n"
    for file_path in request.files:
        content = read_file_content(file_path)
        context += f"=== File: {Path(file_path).name} ===\n{content}\n\n"
    
    try:
        res = requests.post(OLLAMA_API_URL, json={
            "model": AI_MODEL, "prompt": context, "stream": False
        })
        return {"status": "success", "content": res.json().get('response', '')}
    except Exception as e:
        return {"status": "error", "message": str(e)}

@app.get("/api/scan")
def scan_projects():
    """è§¸ç™¼æª”æ¡ˆæƒæ"""
    return {"files": internal_scan_files()}

async def run_weekly_report_job():
    """èƒŒæ™¯ä»»å‹™ï¼šç”Ÿæˆå‘¨å ±"""
    # é€™è£¡æ¨¡æ“¬æƒææœ€è¿‘ 7 å¤©çš„ç•°å‹•
    files = internal_scan_files()
    recent_files = [f for f in files if (time.time() - f['raw_mtime']) < 7*24*3600]
    
    if not recent_files:
        send_teams_card("Weekly Report", "No updates this week.", [])
        return

    # ç°¡å–®åˆ†çµ„ä¸¦ç™¼é€é€šçŸ¥ (é‚è¼¯ç°¡åŒ–ç‰ˆ)
    grouped = defaultdict(list)
    for f in recent_files: grouped[f['project']].append(f['filename'])
    
    summary = f"Detected updates in {len(grouped)} projects. Proceeding with analysis..."
    send_teams_card("Weekly Report Started", summary, [])
    # (å¾ŒçºŒ AI åˆ†æé‚è¼¯åŒä¸Šï¼Œç‚ºç°¡æ½”çœç•¥)

@app.get("/api/trigger_report")
async def trigger_report(bg_tasks: BackgroundTasks):
    bg_tasks.add_task(run_weekly_report_job)
    return {"status": "started", "message": "Report generation running in background..."}

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8001)
